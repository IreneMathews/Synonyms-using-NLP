{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1948042_lab4_NLP_Synonyms.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gUf8R8M0vxa"
      },
      "source": [
        "## Importing important Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-j_BcOp6jdHe",
        "outputId": "eaeacb99-a457-4337-efca-fa9b0d6a2074",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import wordnet as wn \n",
        "import regex as re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1YEKdix05Fr"
      },
      "source": [
        "## Finding out what all exists inside the wordnet package by implementing different functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df8bwaXuPips",
        "outputId": "e7be802d-c565-4d55-fd84-2ea77e1d4a8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "synset = wn.synsets(\"Travel\")\n",
        "print('Word and Type : ' + synset[1].name())\n",
        "print('Synonym of Travel is: ' + synset[1].lemmas()[1].name())\n",
        "print('The meaning of the word : ' + synset[1].definition())\n",
        "print('Example of Travel : ' + str(synset[1].examples()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word and Type : change_of_location.n.01\n",
            "Synonym of Travel is: travel\n",
            "The meaning of the word : a movement through space that changes the location of something\n",
            "Example of Travel : []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arYUFag402PW"
      },
      "source": [
        "## Finding all the synonyms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdAeU_UUQJz5",
        "outputId": "ebe42b00-629e-4fd1-c794-3642df15708f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import wordnet   #Import wordnet from the NLTK\n",
        "syn =[]\n",
        "ant =[]\n",
        "for synset in wordnet.synsets(\"Happy\"):\n",
        "   for lemma in synset.lemmas():\n",
        "      syn.append(lemma.name())    #add the synonyms\n",
        "      if lemma.antonyms():\n",
        "        ant.append(lemma.antonyms()[0].name())\n",
        "print('Synonyms: ' + str(syn))\n",
        "print('Antonyms: ' + str(ant))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Synonyms: ['happy', 'felicitous', 'happy', 'glad', 'happy', 'happy', 'well-chosen']\n",
            "Antonyms: ['unhappy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_jtkIbXms9b"
      },
      "source": [
        "filtered_list=['Nick', 'likes', 'play', 'football', ',', 'however', 'fond', 'tennis', '.']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGRpVgsvmG2k",
        "outputId": "c3e8408b-fd65-4111-933a-e295ad734d54",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(0,len(filtered_list)):\n",
        "  syn =[]\n",
        "  for synset in wordnet.synsets(filtered_list[i]):\n",
        "    for lemma in synset.lemmas():\n",
        "      syn.append(lemma.name())    #add the synonyms\n",
        "  print('Synonyms: ' + str(syn))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Synonyms: ['dent', 'ding', 'gouge', 'nick', 'nick', 'notch', 'nick', 'snick', 'nick', 'snick', 'nick', 'chip', 'nick', 'nick']\n",
            "Synonyms: ['like', 'the_like', 'the_likes_of', 'like', 'ilk', 'wish', 'care', 'like', 'like', 'like', 'like', 'like']\n",
            "Synonyms: ['play', 'drama', 'dramatic_play', 'play', 'play', 'maneuver', 'manoeuvre', 'play', 'play', 'play', 'bid', 'play', 'play', \"child's_play\", 'playing_period', 'period_of_play', 'play', 'free_rein', 'play', 'shimmer', 'play', 'fun', 'play', 'sport', 'looseness', 'play', 'play', 'frolic', 'romp', 'gambol', 'caper', 'turn', 'play', 'gambling', 'gaming', 'play', 'play', 'swordplay', 'play', 'play', 'play', 'act', 'play', 'represent', 'play', 'play', 'spiel', 'play', 'act', 'play', 'act_as', 'play', 'play', 'play', 'recreate', 'play', 'play', 'play', 'play', 'play', 'toy', 'play', 'play', 'run', 'toy', 'fiddle', 'diddle', 'play', 'play', 'dally', 'trifle', 'play', 'play', 'dally', 'toy', 'play', 'flirt', 'play', 'act', 'play', 'roleplay', 'playact', 'play', 'bring', 'work', 'play', 'wreak', 'make_for', 'play', 'play', 'bet', 'wager', 'play', 'play', 'play', 'play', 'meet', 'encounter', 'play', 'take_on', 'play']\n",
            "Synonyms: ['football', 'football_game', 'football']\n",
            "Synonyms: []\n",
            "Synonyms: ['however', 'nevertheless', 'withal', 'still', 'yet', 'all_the_same', 'even_so', 'nonetheless', 'notwithstanding', 'however', 'however', 'however']\n",
            "Synonyms: ['affectionate', 'fond', 'lovesome', 'tender', 'warm', 'adoring', 'doting', 'fond', 'fond', 'partial', 'fond']\n",
            "Synonyms: ['tennis', 'lawn_tennis']\n",
            "Synonyms: []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpzkQtjw0nGC"
      },
      "source": [
        "## Removing Nouns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO9KksEimMPQ",
        "outputId": "fde3c4f5-5b50-4e98-9564-bf7135ab2ea4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "tagged_sentence = nltk.tag.pos_tag(text.split())\n",
        "edited_sentence = [word for word,tag in tagged_sentence if tag != 'NNP' and tag != 'NNPS']\n",
        "#print(' '.join(edited_sentence))\n",
        "edited_sentence"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['likes',\n",
              " 'to',\n",
              " 'play',\n",
              " 'football,',\n",
              " 'however',\n",
              " 'he',\n",
              " 'is',\n",
              " 'not',\n",
              " 'too',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'tennis.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3cDzvZ7mRcb",
        "outputId": "e7bc2c64-403f-4e9e-e39d-abd62416f774",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tagged_sentence = nltk.tag.pos_tag(text.split())\n",
        "edited_sentence = [word for word,tag in tagged_sentence if tag != 'NNP' and tag != 'NNPS']\n",
        "new_text= \" \".join(edited_sentence) \n",
        "text_tokens = word_tokenize(new_text)\n",
        "tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\n",
        "tokens_without_sw"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['likes', 'play', 'football', ',', 'however', 'fond', 'tennis', '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seK72YoO2gfG"
      },
      "source": [
        "Replacing puctuations with whitespace"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY2YjKzZpOpS",
        "outputId": "3daf1253-e946-46ea-dc3c-07ffe7828c8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text1 = re.sub(\"[./!?,']\", \" \", text)\n",
        "text1"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Nick likes to play football  however he is not too fond of tennis '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjsJir9p55iJ"
      },
      "source": [
        "Random choice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fST9RH033ah",
        "outputId": "e99c8074-a1ef-4041-9996-30e40dbc595b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import random\n",
        "d ={'likes': ['like', 'the_like', 'the_likes_of', 'like', 'ilk', 'wish', 'care', 'like', 'like', 'like', 'like', 'like'], 'play': ['play', 'drama', 'dramatic_play', 'play', 'play', 'maneuver', 'manoeuvre', 'play', 'play', 'play', 'bid', 'play', 'play', \"child's_play\", 'playing_period', 'period_of_play', 'play', 'free_rein', 'play', 'shimmer', 'play', 'fun', 'play', 'sport', 'looseness', 'play', 'play', 'frolic', 'romp', 'gambol', 'caper', 'turn', 'play', 'gambling', 'gaming', 'play', 'play', 'swordplay', 'play', 'play', 'play', 'act', 'play', 'represent', 'play', 'play', 'spiel', 'play', 'act', 'play', 'act_as', 'play', 'play', 'play', 'recreate', 'play', 'play', 'play', 'play', 'play', 'toy', 'play', 'play', 'run', 'toy', 'fiddle', 'diddle', 'play', 'play', 'dally', 'trifle', 'play', 'play', 'dally', 'toy', 'play', 'flirt', 'play', 'act', 'play', 'roleplay', 'playact', 'play', 'bring', 'work', 'play', 'wreak', 'make_for', 'play', 'play', 'bet', 'wager', 'play', 'play', 'play', 'play', 'meet', 'encounter', 'play', 'take_on', 'play'], 'football': ['football', 'football_game', 'football'], 'however': ['however', 'nevertheless', 'withal', 'still', 'yet', 'all_the_same', 'even_so', 'nonetheless', 'notwithstanding', 'however', 'however', 'however'], 'fond': ['affectionate', 'fond', 'lovesome', 'tender', 'warm', 'adoring', 'doting', 'fond', 'fond', 'partial', 'fond'], 'tennis': ['tennis', 'lawn_tennis']}\n",
        "capital = random.choice(list(d['play']))\n",
        "capital"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'play'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9qkIqOg0WGr"
      },
      "source": [
        "# Now using all of these to build a Paraphrasing tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKSd3InzYiU8"
      },
      "source": [
        "def rem_stop(text):\n",
        "  text1 = re.sub(\"[./!?,]\", \" \", text) # removing the given punctuations\n",
        "  tagged_sentence = nltk.tag.pos_tag(text1.split())\n",
        "  edited_sentence = [word for word,tag in tagged_sentence if tag != 'NNP' and tag != 'NNPS'] # removing nouns\n",
        "  new_text= \" \".join(edited_sentence) \n",
        "  text_tokens = word_tokenize(new_text) \n",
        "  tokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]  # removing stop words\n",
        "  syn ={}  \n",
        "  # getting synonym for each word\n",
        "  for i in tokens_without_sw:\n",
        "    syn[i] =[]\n",
        "    for synset in wordnet.synsets(i):\n",
        "      for lemma in synset.lemmas():\n",
        "        syn[i].append(lemma.name())    #add the synonyms\n",
        "    #print('Synonyms of '+i+ '  is  :'  + str(syn[i])) # printing individual synonyms\n",
        "  \n",
        "  # selecting one synonym \n",
        "  choose_synonym=[]\n",
        "  for i in tokens_without_sw:\n",
        "     choose_synonym.append(random.choice(list(syn[i])))\n",
        "  #print(choose_synonym)\n",
        "  text_split=word_tokenize(text)\n",
        "  for i in range(0,len(tokens_without_sw)):\n",
        "    for j in range(0,len(text_split)):\n",
        "      if (text_split[j]==tokens_without_sw[i]):\n",
        "        text_split[j]=choose_synonym[i]\n",
        "  paraphrase_text= \" \".join(text_split)\n",
        "  print(paraphrase_text)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vup6KvpfE7-",
        "outputId": "9b2b355f-3240-4dbf-9494-a3beaf52e44b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text = \"Nick likes to play football, however he is not too fond of tennis.\"\n",
        "rem_stop(text)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nick care to play football_game , all_the_same he is not too doting of lawn_tennis .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buAVxfMcm_Lf"
      },
      "source": [
        "## Note\n",
        "\n",
        "Make sure you check the meaning of the sentence that is generated before it used for further processing.\n",
        "\n",
        "\n",
        "You can also use simple Lesk algorithm to obtain the linguistic ambiguity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9-EHkTTnvMV",
        "outputId": "36ab7ea9-1bf1-47a2-cfb8-a9fd29882a87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pywsd  \n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pywsd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/bb/427a49c461b0970c124509f77d2cd75bdca0daa746155c45d065f0af93e3/pywsd-1.2.4.tar.gz (26.8MB)\n",
            "\u001b[K     |████████████████████████████████| 26.8MB 121kB/s \n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from pywsd) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.1.4)\n",
            "Collecting wn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/f6/72db36e8afc977ae1a1cbb22afc77fd9b514e9bc6927ae8f4aae36665961/wn-0.0.23.tar.gz (31.6MB)\n",
            "\u001b[K     |████████████████████████████████| 31.6MB 110kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pywsd) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->pywsd) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->pywsd) (2018.9)\n",
            "Building wheels for collected packages: pywsd, wn\n",
            "  Building wheel for pywsd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pywsd: filename=pywsd-1.2.4-cp36-none-any.whl size=26940455 sha256=719261e72483f674ef8ad0e5078dc7fdbd210a28651f4004dbaf5e45e9ae5b65\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/4d/d2/405b948047f7f3851f16ab9d893ce7c1a3010182900884536b\n",
            "  Building wheel for wn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wn: filename=wn-0.0.23-cp36-none-any.whl size=31792944 sha256=a23561feb034078185073ebb24e44daca6fbbfefa2d6c3b5efdf38fd06323077\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/e3/c4/886021dbf4d758dc3cb9ddaa47d7d6fc895240d83f010e6305\n",
            "Successfully built pywsd wn\n",
            "Installing collected packages: wn, pywsd\n",
            "Successfully installed pywsd-1.2.4 wn-0.0.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4p4Bcrr9Pyn",
        "outputId": "76ac6ca6-c7f5-4e96-e872-cb2ffab8edb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Install pywsd  \n",
        "   \n",
        "#Import functions  \n",
        "from pywsd.lesk import simple_lesk  \n",
        "sentences = ['I went to the bank to deposit my money',  \n",
        "'The river bank was full of dead fishes']  \n",
        "# calling the lesk function and printing results for both the sentences  \n",
        "print (\"Context-1:\", sentences[0])  \n",
        "answer = simple_lesk(sentences[0],'bank')  \n",
        "print (\"Sense:\", answer)  \n",
        "print (\"Definition : \", answer.definition())  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warming up PyWSD (takes ~10 secs)... "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Context-1: I went to the bank to deposit my money\n",
            "Sense: Synset('depository_financial_institution.n.01')\n",
            "Definition :  a financial institution that accepts deposits and channels the money into lending activities\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "took 2.9100539684295654 secs.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP2quf8vno0A"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    }
  ]
}